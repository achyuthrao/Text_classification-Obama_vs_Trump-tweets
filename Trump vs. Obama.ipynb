{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvKbQrULd4la"
   },
   "source": [
    "### Scraping tweets and saving them as txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3287,
     "status": "ok",
     "timestamp": 1585965914679,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "67sDW7yLdtKP",
    "outputId": "41381c1c-1298-4273-c40f-9ffdbf4341a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: getoldtweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from getoldtweets3) (4.2.6)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from getoldtweets3) (1.4.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->getoldtweets3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install getoldtweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpyTKPBYeMCg"
   },
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
    "import GetOldTweets3 as got\n",
    "def scrape_tweets(username):\n",
    "  username = username\n",
    "  count = 2000\n",
    "  # Creation of query object\n",
    "  tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
    "                                          .setMaxTweets(count)\n",
    "  # Creation of list that contains all tweets\n",
    "  tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "  # Creating list of chosen tweet data\n",
    "  user_tweets = [[tweet.text] for tweet in tweets]\n",
    "  return user_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tabndll1eSz-"
   },
   "outputs": [],
   "source": [
    "# Use above function to return tweets of Trump and Obama.\n",
    "# If there is certificate error, try again at another time, maybe several minutes later.\n",
    "# Your code here:\n",
    "obama_tweets=scrape_tweets('BarackObama')\n",
    "trump_tweets=scrape_tweets('realDonaldTrump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96385,
     "status": "ok",
     "timestamp": 1585966007803,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "Baj6ZDZ7kk6g",
    "outputId": "e3abf827-0293-49ec-8c00-eaaaf4b8e209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiPF7dcVehjd"
   },
   "outputs": [],
   "source": [
    "# Save all tweets to two folders\n",
    "# Update the code with your own variables and paths.\n",
    "# The resulted files will be in two folders just like IMDB data.\n",
    "for i in range(0,len(trump_tweets)):\n",
    "  path='/content/drive/My Drive/Obama vs Trump Tweets classification/Trump/trump'+str(i)+'.txt'\n",
    "  with open(path, \"w\") as output:\n",
    "    output.write(str(trump_tweets[i]))\n",
    "for i in range(0,len(obama_tweets)):\n",
    "  path='/content/drive/My Drive/Obama vs Trump Tweets classification/Obama/obama'+str(i)+'.txt'\n",
    "  with open(path, \"w\") as output:\n",
    "    output.write(str(obama_tweets[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqshhrcNgP48"
   },
   "source": [
    "# Loading data and prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 125863,
     "status": "ok",
     "timestamp": 1585966037301,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "l-3u4Cy5gTqZ",
    "outputId": "429d516f-39f2-41b9-f368-b9ec9baf8b10"
   },
   "source": [
    "#Load the data you just saved from your drive\n",
    "import os\n",
    "\n",
    "as3_dir = '/content/drive/My Drive/Obama vs Trump Tweets classification'\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "count = 0\n",
    "for label_type in ['Obama/', 'Trump/']:\n",
    "    dir_name = os.path.join(as3_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            count = count + 1\n",
    "            print(count)\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'Obama/':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 128319,
     "status": "ok",
     "timestamp": 1585966039786,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "c--tDdA4gdBT",
    "outputId": "6d23962f-0057-48d4-acd2-017f32f9fde1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10172 unique tokens.\n",
      "Shape of data tensor: (4000, 140)\n",
      "Shape of label tensor: (4000,)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, pad and prepare training and validation data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 140  # cutting tweets after 140 words\n",
    "training_samples = 2000  # Training using 2000 samples\n",
    "validation_samples = 2000  # Validating on 2000 samples\n",
    "max_words = 5000  # Considering the top 10,000 words in the dataset\n",
    "\n",
    "# This class allows to vectorize a text corpus, by turning each text into either a sequence of integers\n",
    "# omits common characters \n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# fit_on_texts means it learns the indices of the words\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# the sequences are comprised of those indices\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# in case of low word counts, we need to pad sequences\n",
    "# so that they are uniform length\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# our labels, which were previously stored as a list [],\n",
    "# are now converted to a numpy array for modeling\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples] # from 0 to (2000) training samples\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 140919,
     "status": "ok",
     "timestamp": 1585966052398,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "Dy_pnmUQH-fT",
    "outputId": "7c0a7cd8-f277-451c-bd37-f801e399f7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Downloaded GloVe word embeddings into my gdrive from https://nlp.stanford.edu/projects/glove/\n",
    "glove_dir = '/content/drive/My Drive/GLoVE embeddings/'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_dim = 100 # this is the dimension of the embeddings file we imported\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWWG_J0Tg7O8"
   },
   "source": [
    "## Fitting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 183559,
     "status": "ok",
     "timestamp": 1585966095049,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "WdpPWa8zhEsr",
    "outputId": "c330baed-7ab9-4177-9348-4c70bf6bdb32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 140, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,080,501\n",
      "Trainable params: 1,080,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 8s 207ms/step - loss: 0.4750 - acc: 0.8025 - val_loss: 0.2757 - val_acc: 0.8870\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 8s 197ms/step - loss: 0.1729 - acc: 0.9425 - val_loss: 0.2297 - val_acc: 0.9080\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 8s 194ms/step - loss: 0.0679 - acc: 0.9805 - val_loss: 0.1101 - val_acc: 0.9590\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 8s 195ms/step - loss: 0.0316 - acc: 0.9925 - val_loss: 0.1340 - val_acc: 0.9570\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 8s 198ms/step - loss: 0.0152 - acc: 0.9950 - val_loss: 0.1176 - val_acc: 0.9645\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# LSTM model with no pre-trained embeddings \n",
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model1.add(tf.keras.layers.LSTM(100))\n",
    "model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(x_val, y_val))\n",
    "#model1.save_weights('predicting_Obama_vs_Trump_tweets_model1.h5')\n",
    "model1.save('predicting_Obama_vs_Trump_tweets_model1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185830,
     "status": "ok",
     "timestamp": 1585966097332,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "d1Q2Ce2P4fz3",
    "outputId": "50c6b644-0a4d-4a28-c1d1-b4c9fd34deb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-9ea7bdccf773>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       987\n",
      "           1       0.96      0.97      0.96      1013\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model1=load_model('predicting_Obama_vs_Trump_tweets_model1.h5')\n",
    "\n",
    "#y_pred = model1.predict(x_val, verbose=0)\n",
    "y_pred = model1.predict_classes(x_val, verbose=0)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 260565,
     "status": "ok",
     "timestamp": 1585966172078,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "fR0iSGcssZVf",
    "outputId": "dba79804-971d-4769-f23c-0976447a7750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 140, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,161,001\n",
      "Trainable params: 1,161,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 14s 355ms/step - loss: 0.4969 - acc: 0.7800 - val_loss: 0.3207 - val_acc: 0.8535\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 13s 324ms/step - loss: 0.1978 - acc: 0.9290 - val_loss: 0.1730 - val_acc: 0.9360\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 13s 332ms/step - loss: 0.0806 - acc: 0.9745 - val_loss: 0.1436 - val_acc: 0.9480\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 13s 336ms/step - loss: 0.0394 - acc: 0.9890 - val_loss: 0.1276 - val_acc: 0.9515\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 13s 330ms/step - loss: 0.0199 - acc: 0.9945 - val_loss: 0.1294 - val_acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional LSTM with no pre-trained embeddings\n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)))\n",
    "model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model2.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model2.save('predicting_Obama_vs_Trump_tweets_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 264254,
     "status": "ok",
     "timestamp": 1585966175776,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "PpNbMVZi5VJ2",
    "outputId": "05a07f5f-b815-423a-fb5a-8b9d4cc9490a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Obama       0.95      0.96      0.96       987\n",
      "       Trump       0.96      0.96      0.96      1013\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Obama', 'Trump']\n",
    "y_pred = model2.predict_classes(x_val, verbose=0)\n",
    "print(classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 290374,
     "status": "ok",
     "timestamp": 1585966201907,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "2ZbS1YbuuRE6",
    "outputId": "f5e3edee-ccd0-4091-c310-699920bfd331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 140, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 138, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 69, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,062,933\n",
      "Trainable params: 1,062,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.4837 - acc: 0.7755 - val_loss: 0.2668 - val_acc: 0.9065\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 4s 112ms/step - loss: 0.1393 - acc: 0.9555 - val_loss: 0.1357 - val_acc: 0.9465\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.0509 - acc: 0.9855 - val_loss: 0.0964 - val_acc: 0.9650\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.0235 - acc: 0.9955 - val_loss: 0.1006 - val_acc: 0.9665\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.1228 - val_acc: 0.9665\n"
     ]
    }
   ],
   "source": [
    "# 1D convolution then LSTM with no pre-trained embeddings\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model3.add(tf.keras.layers.Convolution1D(filters=32, kernel_size=3,activation='relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model3.add(tf.keras.layers.LSTM(100))\n",
    "model3.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model3.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model3.save('predicting_Obama_vs_Trump_tweets_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 291899,
     "status": "ok",
     "timestamp": 1585966203441,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "nr7uUsnD5rL1",
    "outputId": "ec1b4dce-7ff4-41ef-80e4-e11e159da7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Obama       0.96      0.98      0.97       987\n",
      "       Trump       0.98      0.96      0.97      1013\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Obama', 'Trump']\n",
    "y_pred = model3.predict_classes(x_val, verbose=0)\n",
    "print(classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 375946,
     "status": "ok",
     "timestamp": 1585966287497,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "IIIxWg3EzYkZ",
    "outputId": "8218eedc-b33b-411e-964d-b9f0ffdaa6a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 140, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,080,501\n",
      "Trainable params: 1,080,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 0.3832 - acc: 0.8310 - val_loss: 0.3007 - val_acc: 0.8675\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2680 - acc: 0.8840 - val_loss: 0.2833 - val_acc: 0.8805\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.2276 - acc: 0.8960 - val_loss: 0.2379 - val_acc: 0.9010\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 0.1976 - acc: 0.9160 - val_loss: 0.3305 - val_acc: 0.8620\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1754 - acc: 0.9290 - val_loss: 0.2621 - val_acc: 0.8925\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.1518 - acc: 0.9375 - val_loss: 0.2271 - val_acc: 0.9155\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 0.1324 - acc: 0.9465 - val_loss: 0.2308 - val_acc: 0.9210\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.1141 - acc: 0.9565 - val_loss: 0.2078 - val_acc: 0.9210\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.1004 - acc: 0.9645 - val_loss: 0.2877 - val_acc: 0.8950\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.0889 - acc: 0.9710 - val_loss: 0.2641 - val_acc: 0.9100\n"
     ]
    }
   ],
   "source": [
    "# LSTM with pre-trained GloVe 100D embeddings\n",
    "model4 = tf.keras.models.Sequential()\n",
    "model4.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model4.add(tf.keras.layers.LSTM(100))\n",
    "model4.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model4.summary()\n",
    "\n",
    "model4.layers[0].set_weights([embedding_matrix])\n",
    "model4.layers[0].trainable = False\n",
    "\n",
    "model4.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model4.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=25,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model4.save_weights('predicting_Obama_vs_Trump_tweets_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 378193,
     "status": "ok",
     "timestamp": 1585966289746,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "rUgUdKUp7Pvt",
    "outputId": "32c5318b-e7b3-4881-a15f-bbb7d2904386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Obama       0.91      0.90      0.91       987\n",
      "       Trump       0.91      0.92      0.91      1013\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.91      0.91      0.91      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Obama', 'Trump']\n",
    "y_pred = model4.predict_classes(x_val, verbose=0)\n",
    "print(classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 527256,
     "status": "ok",
     "timestamp": 1585966438818,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "kClt7OW707pd",
    "outputId": "07b21a49-8db6-43bf-b92d-4c1c00bb0298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 140, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,161,001\n",
      "Trainable params: 161,001\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 15s 184ms/step - loss: 0.3762 - acc: 0.8410 - val_loss: 0.3165 - val_acc: 0.8695\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 14s 178ms/step - loss: 0.2757 - acc: 0.8840 - val_loss: 0.3630 - val_acc: 0.8305\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 14s 179ms/step - loss: 0.2313 - acc: 0.8995 - val_loss: 0.2415 - val_acc: 0.8985\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 14s 181ms/step - loss: 0.2023 - acc: 0.9110 - val_loss: 0.2964 - val_acc: 0.8730\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 14s 180ms/step - loss: 0.1743 - acc: 0.9300 - val_loss: 0.2223 - val_acc: 0.9155\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 14s 179ms/step - loss: 0.1630 - acc: 0.9390 - val_loss: 0.2431 - val_acc: 0.9035\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 15s 182ms/step - loss: 0.1390 - acc: 0.9465 - val_loss: 0.2325 - val_acc: 0.9170\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 14s 177ms/step - loss: 0.1280 - acc: 0.9530 - val_loss: 0.2153 - val_acc: 0.9140\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 14s 181ms/step - loss: 0.1044 - acc: 0.9590 - val_loss: 0.2498 - val_acc: 0.9175\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 15s 181ms/step - loss: 0.0900 - acc: 0.9685 - val_loss: 0.2448 - val_acc: 0.9080\n"
     ]
    }
   ],
   "source": [
    "# Bi-directional LSTM with pre-trained GloVe embeddings\n",
    "model5 = tf.keras.models.Sequential()\n",
    "model5.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
    "model5.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)))\n",
    "model5.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model5.summary()\n",
    "\n",
    "model5.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model5.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=25,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model5.save('predicting_Obama_vs_Trump_tweets_model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530889,
     "status": "ok",
     "timestamp": 1585966442460,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "aN9_31IG5wn2",
    "outputId": "e342acee-7d22-450f-b058-fab241e3af2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Obama       0.91      0.90      0.91       987\n",
      "       Trump       0.91      0.91      0.91      1013\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.91      0.91      0.91      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Obama', 'Trump']\n",
    "y_pred = model5.predict_classes(x_val, verbose=0)\n",
    "print(classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 588762,
     "status": "ok",
     "timestamp": 1585966500343,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "Vxd48r__1uhV",
    "outputId": "70dc1a04-4a0c-4f17-8233-ff715560bcc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 140, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 138, 32)           9632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 69, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,062,933\n",
      "Trainable params: 62,933\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 6s 74ms/step - loss: 0.3939 - acc: 0.8210 - val_loss: 0.3040 - val_acc: 0.8740\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 6s 69ms/step - loss: 0.2702 - acc: 0.8905 - val_loss: 0.2780 - val_acc: 0.8850\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 0.2087 - acc: 0.9125 - val_loss: 0.2395 - val_acc: 0.9020\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.1710 - acc: 0.9300 - val_loss: 0.2231 - val_acc: 0.9110\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 0.1452 - acc: 0.9445 - val_loss: 0.2177 - val_acc: 0.9085\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 0.1201 - acc: 0.9535 - val_loss: 0.2317 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 0.0907 - acc: 0.9660 - val_loss: 0.3047 - val_acc: 0.8880\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 0.0884 - acc: 0.9725 - val_loss: 0.2128 - val_acc: 0.9255\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 6s 69ms/step - loss: 0.0626 - acc: 0.9795 - val_loss: 0.2399 - val_acc: 0.9175\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 0.0527 - acc: 0.9855 - val_loss: 0.2488 - val_acc: 0.9205\n"
     ]
    }
   ],
   "source": [
    "# 1D convolution then LSTM with pre-trained GloVe embeddings\n",
    "model6 = tf.keras.models.Sequential()\n",
    "model6.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen,weights=[embedding_matrix],trainable=False))\n",
    "model6.add(tf.keras.layers.Convolution1D(filters=32, kernel_size=3,activation='relu'))\n",
    "model6.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model6.add(tf.keras.layers.LSTM(100))\n",
    "model6.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model6.summary()\n",
    "\n",
    "model6.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model6.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=25,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model6.save('predicting_Obama_vs_Trump_tweets_model6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 590247,
     "status": "ok",
     "timestamp": 1585966501837,
     "user": {
      "displayName": "Achyuth Sankineni",
      "photoUrl": "",
      "userId": "09270309325006749696"
     },
     "user_tz": 240
    },
    "id": "CUsTIofl515j",
    "outputId": "0fde7ac2-65e6-4a99-caaf-7294657f4502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Obama       0.92      0.92      0.92       987\n",
      "       Trump       0.92      0.92      0.92      1013\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.92      0.92      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Obama', 'Trump']\n",
    "y_pred = model6.predict_classes(x_val, verbose=0)\n",
    "print(classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHhinvRchV1f"
   },
   "source": [
    "## Insight:\n",
    "Performance of the models with new embedding beign trained on the go rather than using GloVe embeddings is better. This tells us that the new embeddings being learned by the models are optimised to identify if the words would be used by Trump or Obama. i.e. two words would have close embeddings if they are more likely to be used by Obama but not Trump or viceversa. But GloVe embeddings would be similar for the words that are more interchangeable in a general context.\n",
    "\n",
    "The fact that using GloVe embeddings is having lower accuracy shows that both Obama & Trump uses different words to convey similar message. If both of them were using the same words the models with new embeddings being learnt would have shown similar performance as the ones using GloVe embeddings. Having similar vector for different words that would convey similar message in GloVe embedding makes it difficult to differtiate between Obama & Trump tweets."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3_ Trump vs. Obama_ars19020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
